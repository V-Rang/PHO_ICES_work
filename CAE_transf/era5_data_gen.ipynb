{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc4c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def modes_for_energy(S, energy_frac=0.95):\n",
    "    \"\"\"\n",
    "    Compute the minimal number of singular modes needed to capture\n",
    "    at least `energy_frac` (default 0.95) of the total energy of S.\n",
    "    \"\"\"\n",
    "    # Full SVD (you can swap in a truncated SVD if S is huge)\n",
    "    U, s, Vt = np.linalg.svd(S, full_matrices=False)\n",
    "    # Energy in each mode is sigma_i^2\n",
    "    energies = s**2\n",
    "    # Cumulative energy ratio\n",
    "    cum_energy = np.cumsum(energies) / np.sum(energies)\n",
    "    # Find the first k where cum_energy[k-1] >= energy_frac\n",
    "    k95 = np.searchsorted(cum_energy, energy_frac) + 1\n",
    "    return k95, cum_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76cc3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_path = \"gs://weatherbench2/datasets/era5/1959-2022-full_37-1h-0p25deg-chunk-1.zarr-v2/\"\n",
    "import xarray as xr\n",
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ds = xr.open_zarr(obs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98463c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "\n",
    "    # \"train\": ['2019-01-01T00:00:00', '2019-02-11T00:00:00'], v1\n",
    "    # \"test\":  ['2019-05-10T00:00:00', '2019-05-15T03:00:00'],\n",
    "    # \"val\":   ['2019-07-20T00:00:00', '2019-07-30T03:00:00'],\n",
    "\n",
    "    \"train\": ['2019-01-01T00:00:00', '2019-03-11T00:00:00'],\n",
    "    \"test\":  ['2019-05-10T00:00:00', '2019-06-15T03:00:00'],\n",
    "    \"val\":   ['2019-07-20T00:00:00', '2019-08-30T03:00:00'],\n",
    "\n",
    "    # \"train\": ['2019-01-01T00:00:00', '2019-01-01T04:00:00'],\n",
    "    # \"test\":  ['2019-05-10T00:00:00', '2019-05-10T03:00:00'],\n",
    "    # \"val\":   ['2019-07-20T00:00:00', '2019-07-20T02:00:00'],\n",
    "\n",
    "}\n",
    "\n",
    "lat_slice = slice(50., 10.)    \n",
    "lon_slice = slice(260., 295.)\n",
    "\n",
    "# vars_list = ['10m_u_component_of_wind', '10m_v_component_of_wind']\n",
    "\n",
    "vars_list = ['10m_u_component_of_wind']\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for split, timerange in splits.items():\n",
    "    sub = ds[vars_list] \\\n",
    "          .sel(latitude=lat_slice,\n",
    "               longitude=lon_slice,\n",
    "               time=slice(*timerange))\n",
    "    da = sub.to_array(dim=\"variable\") \\\n",
    "            .transpose(\"time\", \"variable\", \"latitude\", \"longitude\")\n",
    "\n",
    "    dataset[split] = {\n",
    "        \"data\":     da.values,         # (T, V, Y, X)\n",
    "        \"times\":    da.time.values,\n",
    "        \"lat_vals\": da.latitude.values,\n",
    "        \"lon_vals\": da.longitude.values,\n",
    "    }\n",
    "\n",
    "\n",
    "train_data = dataset['train']['data']\n",
    "S_train_org = train_data[:,0,:,:]\n",
    "S_train = S_train_org.reshape((S_train_org.shape[0], S_train_org.shape[1] * S_train_org.shape[2])).T\n",
    "\n",
    "test_data = dataset['test']['data']\n",
    "S_test_org = test_data[:,0,:,:]\n",
    "S_test = S_test_org.reshape((S_test_org.shape[0], S_test_org.shape[1] * S_test_org.shape[2])).T\n",
    "\n",
    "val_data = dataset['val']['data']\n",
    "S_val_org = val_data[:,0,:,:]\n",
    "S_val = S_val_org.reshape((S_val_org.shape[0], S_val_org.shape[1] * S_val_org.shape[2])).T\n",
    "\n",
    "# min_train_val, max_train_val = S_train.min(), S_train.max()\n",
    "\n",
    "# S_train_normalized = (S_train - min_train_val)/ (max_train_val - min_train_val)\n",
    "# S_val_normalized = (S_val - min_train_val)/ (max_train_val - min_train_val)\n",
    "# S_test_normalized = (S_test - min_train_val)/ (max_train_val - min_train_val)\n",
    "\n",
    "X_train = S_train[:, :-1]\n",
    "Y_train = S_train[:, 1: ]\n",
    "\n",
    "# U_vals, sing_vals, Vt_vals = np.linalg.svd(S_train, full_matrices= False)\n",
    "U_vals, sing_vals, Vt_vals = np.linalg.svd(X_train, full_matrices= False)\n",
    "\n",
    "train_vals =  {'data': S_train, 'time': dataset['train']['times'] }\n",
    "test_vals =   {'data': S_test, 'time':  dataset['test']['times'] }\n",
    "val_vals =    {'data': S_val, 'time':   dataset['val']['times'] }\n",
    "\n",
    "r95, cum_e = modes_for_energy(S_train, 0.95)\n",
    "\n",
    "# u_10m_comp_vals_3 = {\n",
    "#     'lat_vals': dataset['train']['lat_vals'],\n",
    "#     'lon_vals': dataset['train']['lon_vals'],\n",
    "#     'train': train_vals,\n",
    "#     'test': test_vals,\n",
    "#     'val': val_vals,\n",
    "#     'U_vals': U_vals,\n",
    "#     'sing_vals': sing_vals,\n",
    "#     'Vt_vals': Vt_vals,\n",
    "#     'r95': r95,\n",
    "#     'min_train_val': min_train_val,\n",
    "#     'max_train_val': max_train_val,\n",
    "# }\n",
    "\n",
    "# with open('../data/u_10m_comp_vals_3_normalized.pkl', 'wb') as f:\n",
    "#     pickle.dump(u_10m_comp_vals_3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb11498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1657, 161, 141) (868, 161, 141) (988, 161, 141)\n"
     ]
    }
   ],
   "source": [
    "# print(S_train.shape, X_train.shape, U_vals.shape)\n",
    "\n",
    "print(S_train_org.shape, S_test_org.shape, S_val_org.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df6ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22701, 1657)\n",
      "(22701, 868)\n",
      "(22701, 988)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/u_10m_comp_vals_3_normalized.pkl', 'rb') as f:\n",
    "    sample = pickle.load(f)\n",
    "\n",
    "# print(sample['train']['data'].shape) # (22701, 985) # v1\n",
    "# print(sample['test']['data'].shape) # (22701, 124)\n",
    "# print(sample['val']['data'].shape) # (22701, 244)\n",
    "\n",
    "print(sample['train']['data'].shape) # (22701, 1657)\n",
    "print(sample['test']['data'].shape) # (22701, 868)\n",
    "print(sample['val']['data'].shape) # (22701, 988)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c117f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22701, 1657)\n",
      "(22701, 868)\n",
      "(22701, 988)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/u_10m_comp_vals_3_normalized.pkl', 'rb') as f:\n",
    "    sample = pickle.load(f)\n",
    "\n",
    "print(sample['train']['data'].shape) # (22701, 985)\n",
    "print(sample['test']['data'].shape) # (22701, 124)\n",
    "print(sample['val']['data'].shape) # (22701, 244)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00a3dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(S_train_normalized.shape) # (22701, 1657)\n",
    "# print(S_train_normalized.min(), \":\", S_train_normalized.max())\n",
    "# print(S_val_normalized.min(), \":\", S_val_normalized.max())\n",
    "# print(S_test_normalized.min(), \":\", S_test_normalized.max())\n",
    "# U_vals, sing_vals, Vt_vals\n",
    "\n",
    "# print(U_vals.min(), \":\", U_vals.max()) # -0.09883697 : 0.065371275\n",
    "import jax.numpy as jnp\n",
    "l_val = 20\n",
    "r_val = 8\n",
    "p_val = 20 # number of non-linearities to select from r_val x len(library)\n",
    "\n",
    "U_l = U_vals[:, : l_val]\n",
    "Sig_l = sing_vals[: l_val]\n",
    "Vt_l = Vt_vals[: l_val, :]\n",
    "\n",
    "# print(U_l.min(), \":\", U_l.max()) # -0.042215355 : 0.043401726\n",
    "\n",
    "phi_mat = jnp.vstack([\n",
    "    jnp.eye(r_val, dtype=jnp.float32),\n",
    "    jnp.zeros((l_val - r_val, r_val), dtype=jnp.float32),\n",
    "])\n",
    "\n",
    "U_r = U_l @ phi_mat\n",
    "X_hat = U_r.T @ X_train\n",
    "\n",
    "# print(X_hat.min(), \":\", X_hat.max()) # -76.05583 : 14.7015705\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
